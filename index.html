<h1>éƒ­ç»é˜³ | ä¸ªäººä¸»é¡µ</h1>
<p><strong>Shaoyang GUO</strong><br>
åŒ—äº¬å¤§å­¦ç‰©ç†å­¦é™¢ Â· æœ¬ç§‘ç”Ÿ (2023çº§)</p>
<p><strong>ç ”ç©¶é¢†åŸŸï¼š</strong> äººå·¥æ™ºèƒ½ã€å…·èº«æ™ºèƒ½ï¼ˆVisionâ€“Languageâ€“Action, VLAï¼‰<br>
<strong>ç ”ç©¶å…´è¶£ï¼š</strong> å…·èº«æ™ºèƒ½ Â· å¤§æ¨¡å‹æ¨ç† Â· å¤§æ¨¡å‹å®‰å…¨ Â· AI for Science</p>
<hr>
<h2>æ•™è‚²èƒŒæ™¯</h2>
<ul>
<li><strong>åŒ—äº¬å¤§å­¦ç‰©ç†å­¦é™¢ | æœ¬ç§‘ç‰©ç†å­¦ä¸“ä¸š</strong> (2023.09 â€“ é¢„è®¡2027.07)
</li>
</ul>
<hr>
<h2>ç ”ç©¶ç»å†</h2>
<h3>PKU-PsiRobot å®éªŒå®¤ï¼ˆ2025.03 â€“ è‡³ä»Šï¼‰</h3>
<ul>
<li><strong>å¯¼å¸ˆï¼šæ¨è€€ä¸œ åŠ©ç†æ•™æˆ</strong></li>
<li>ä»äº‹ Visionâ€“Languageâ€“Action (VLA) æ¨¡å‹ç ”ç©¶ï¼Œæ¢ç´¢å…·èº«æ™ºèƒ½é¢†åŸŸä¸­çš„ç‰©ç†æ¨ç†åŠå…¶å®é™…åº”ç”¨ã€‚</li>
</ul>
<h3>PKU LHCb å®éªŒç»„ï¼ˆ2023.05 â€“ 2024.05ï¼‰</h3>
<ul>
<li><strong>å¯¼å¸ˆï¼šå¼ è‰³å¸­ åŠ©ç†æ•™æˆ</strong></li>
<li>å‚ä¸é«˜èƒ½ç‰©ç† LHCb å®éªŒæ•°æ®åˆ†æï¼Œç§¯ç´¯äº†ä¸°å¯Œçš„æ•°æ®å¤„ç†å’Œç»Ÿè®¡åˆ†æç»éªŒã€‚</li>
</ul>
<hr>
<h2>å­¦æœ¯æˆæœ</h2>
<ul>
<li><strong>PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models</strong><br>
<em>arXiv:2504.16074</em>, 2025
<ul>
<li>åˆä½œè€…ï¼šShi Qiu ç­‰</li>
<li>æœ¬äººè´¡çŒ®ï¼š
<ol>
<li>è®¾è®¡ Data curation æµæ°´çº¿ï¼Œè§„èŒƒé«˜è´¨é‡ç‰©ç†æ•°æ®é‡‡é›†æµç¨‹ã€‚</li>
<li>åˆ›æ–°æ€§åœ°æå‡ºå¹¶åº”ç”¨â€œè¡¨è¾¾å¼æ ‘ç¼–è¾‘è·ç¦»â€ï¼Œé‡åŒ–è¯„ä¼°ç‰©ç†æ¨ç†ç­”æ¡ˆçš„ç›¸ä¼¼æ€§ä¸å‡†ç¡®æ€§ã€‚</li>
</ol>
</li>
</ul>
</li>
</ul>
<hr>
<h2>è£èª‰ä¸å¥–åŠ±</h2>
<ul>
<li>åŒ—äº¬å¤§å­¦å›½å®¶å¥–å­¦é‡‘ï¼ˆ2023â€“2024, 2024â€“2025ï¼‰</li>
<li>å…¨å›½ä¸­å­¦ç”Ÿç‰©ç†ç«èµ› (CPhO) é‡‘ç‰Œ</li>
<li>å…¨å›½ä¿¡æ¯å­¦å¥¥æ—åŒ¹å…‹è”èµ› (NOIP 2020) ä¸€ç­‰å¥–</li>
<li>å…¨å›½é’å°‘å¹´ä¿¡æ¯å­¦å¥¥æ—åŒ¹å…‹ç«èµ› (CSP-S 2020) ä¸€ç­‰å¥–</li>
</ul>
<hr>
<h2>æŠ€èƒ½æ¦‚è§ˆ</h2>
<table>
<thead>
<tr>
<th>é¢†åŸŸ</th>
<th>è¯´æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>ç¼–ç¨‹è¯­è¨€</strong></td>
<td>Python, C/C++, MATLAB, Wolfram Alpha</td>
</tr>
<tr>
<td><strong>æ·±åº¦å­¦ä¹ ä¸æ¡†æ¶</strong></td>
<td>PyTorch, TensorFlow, vLLM, DeepSpeed</td>
</tr>
<tr>
<td><strong>å®éªŒä¸æ•°æ®å¤„ç†ç´ å…»</strong></td>
<td>é«˜èƒ½ç‰©ç†å®éªŒä¸“ä¸šæ•°æ®åˆ†æç»éªŒï¼Œæ›¾ä»»åŒ—äº¬å¤§å­¦ CUPT é˜Ÿé•¿</td>
</tr>
<tr>
<td><strong>é«˜æ€§èƒ½è®¡ç®—</strong></td>
<td>ä¸¤å¹´ä»¥ä¸ŠæœåŠ¡å™¨ç®¡ç†ä¸ä½¿ç”¨ç»éªŒï¼Œå…·å¤‡è¯¾ç¨‹çº§æœºå™¨å­¦ä¹ ä¸æ¨¡å‹è®­ç»ƒç»éªŒ</td>
</tr>
<tr>
<td><strong>è¯­è¨€èƒ½åŠ›</strong></td>
<td>è‹±è¯­ (CET-6: 657, GRE: 320)ï¼›æ±‰è¯­ï¼ˆæ¯è¯­ï¼‰</td>
</tr>
</tbody>
</table>
<hr>
<h2>è”ç³»æ–¹å¼</h2>
<ul>
<li>ğŸ“§ é‚®ç®±ï¼š<a href="mailto:guoshaoyang@stu.pku.edu.cn">guoshaoyang@stu.pku.edu.cn</a></li>
<li>ğŸ”— GitHubï¼š<a href="https://github.com/guoshaoyang-pku">guoshaoyang-pku</a></li>
<li>ğŸŒ ä¸»é¡µï¼š<a href="https://github.com/guoshaoyang-pku/guoshaoyang-pku.github.io">ä¸ªäººä¸»é¡µ</a></li>
</ul>
<h1>Shaoyang GUO | Personal Homepage</h1>
<p><strong>Undergraduate Student, School of Physics, Peking University (Class of 2023)</strong></p>
<p><strong>Research Area:</strong> Artificial Intelligence, Embodied Intelligence (Visionâ€“Languageâ€“Action, VLA)<br>
<strong>Research Interests:</strong> Embodied Intelligence Â· Large-Model Reasoning Â· Model Safety Â· AI for Science</p>
<hr>
<h2>Education</h2>
<ul>
<li><strong>School of Physics, Peking University</strong> | B.S. in Physics <em>(Sep 2023 â€“ Expected Jul 2027)</em>
</li>
</ul>
<hr>
<h2>Research Experience</h2>
<h3>PKU-PsiRobot Lab <em>(Mar 2025 â€“ Present)</em></h3>
<ul>
<li><strong>Advisor:</strong> Prof. Yaodong Yang (Assistant Professor)</li>
<li>Conducting research on Visionâ€“Languageâ€“Action (VLA) models, focusing on physical reasoning tasks and real-world embodied intelligence applications.</li>
</ul>
<h3>PKU LHCb Experimental Group <em>(May 2023 â€“ May 2024)</em></h3>
<ul>
<li><strong>Advisor:</strong> Prof. Yanxi Zhang (Assistant Professor)</li>
<li>Conducted data analysis for high-energy physics experiments (LHCb), accumulating extensive experience in data processing and statistical methodologies.</li>
</ul>
<hr>
<h2>Publications</h2>
<ul>
<li><strong>PHYBench: Holistic Evaluation of Physical Perception and Reasoning in Large Language Models</strong><br>
<em>arXiv:2504.16074</em>, 2025
<ul>
<li>Collaborators: Shi Qiu et al.</li>
<li>Personal contributions:
<ol>
<li>Designed and implemented data curation pipelines for high-quality physics data collection.</li>
<li>Introduced the &quot;Expression Tree Edit Distance&quot; metric to quantitatively evaluate the similarity and accuracy of physical reasoning answers.</li>
</ol>
</li>
</ul>
</li>
</ul>
<hr>
<h2>Honors &amp; Awards</h2>
<ul>
<li>National Scholarship, Peking University (2023â€“2024, 2024â€“2025)</li>
<li>Gold Medal, Chinese Physics Olympiad (CPhO)</li>
<li>First Prize, National Olympiad in Informatics in Provinces (NOIP 2020)</li>
<li>First Prize, Chinese Secondary-School Programming Contest (CSP-S 2020)</li>
</ul>
<hr>
<h2>Technical Skills</h2>
<table>
<thead>
<tr>
<th>Area</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Programming Languages</strong></td>
<td>Python, C/C++, MATLAB, Wolfram Alpha</td>
</tr>
<tr>
<td><strong>Deep Learning Frameworks</strong></td>
<td>PyTorch, TensorFlow, vLLM, DeepSpeed</td>
</tr>
<tr>
<td><strong>Experiment &amp; Data Skills</strong></td>
<td>Experienced in high-energy physics data analysis; Team leader, PKU CUPT</td>
</tr>
<tr>
<td><strong>High-Performance Computing</strong></td>
<td>Over two years of experience in server management and machine-learning model training</td>
</tr>
<tr>
<td><strong>Languages</strong></td>
<td>English (CET-6: 657, GRE: 320), Chinese (Native)</td>
</tr>
</tbody>
</table>
<hr>
<h2>Contact Information</h2>
<ul>
<li>ğŸ“§ Email: <a href="mailto:guoshaoyang@stu.pku.edu.cn">guoshaoyang@stu.pku.edu.cn</a></li>
<li>ğŸ”— GitHub: <a href="https://github.com/guoshaoyang-pku">guoshaoyang-pku</a></li>
<li>ğŸŒ Homepage: <a href="https://github.com/guoshaoyang-pku/guoshaoyang-pku.github.io">Personal Website</a></li>
</ul>
